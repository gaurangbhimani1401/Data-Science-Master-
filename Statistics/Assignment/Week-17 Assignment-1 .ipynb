{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d404b64-694e-43f8-92bb-0681a6330005",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029916b-e55f-423f-8ac3-f2673855da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 1:-Bayes theorem, named after the Reverend Thomas Bayes, is a fundamental theorem in probability theory. \n",
    "It describes the probability of an event, based on prior knowledge of conditions that might be related to the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc9b6c-94dc-4322-b108-8364610518ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes theorem is particularly useful in machine learning and statistics, especially in Bayesian statistics. \n",
    "It allows us to update probabilities as new evidence becomes available. \n",
    "The theorem is a cornerstone in Bayesian inference, a statistical approach that uses probability to express uncertainty in statistical estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b1bbd8-32b5-4b18-83e2-ccc280a6f6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99650a52-8ec2-4076-bdbc-a988f40f874b",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac486b-2c52-4f82-8e85-09fc182c7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 2:- P(A|B)=P(B|A).P(A)/P(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f50a533-6f06-4e0f-9b01-8a41d2fba560",
   "metadata": {},
   "outputs": [],
   "source": [
    "P(A|B)=is the probability of event A given that event B has occurred.\n",
    "P(B|A)= is the probability of event B given that event A has occurred.\n",
    "P(A)=is the probability of event A.\n",
    "P(B)=is the probability of event B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5de2cd-cfea-4816-87df-6c18c7b413dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74f46fda-0afb-4da7-8fe7-91dfacbf02d4",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dda56a-c31e-4798-9387-6c662fc66803",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 3:-Bayes theorem is used in various fields and applications, and its practical use can be summarized in the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc02a4-02fa-4953-b4e8-4c759a1d1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define Events A and B:\n",
    "    A is the event for which you want to calculate the probability.\n",
    "    B is the observed evidence or new information.\n",
    "    \n",
    "Assign Prior Probabilities:\n",
    "    P(A): The prior probability of event A based on existing knowledge or beliefs.\n",
    "    P(B|A):The probability of observing evidence B given that A is true.\n",
    "    \n",
    "Calculate Likelihood:\n",
    "    P(B): The total probability of observing evidence B, regardless of whether A is true or not.\n",
    "    P(B∣A′): The probability of observing evidence B given that A is false (complement of A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36314f31-19df-445a-8c91-484dd4f948a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "This process is commonly used in Bayesian statistics for updating beliefs based on new data.\n",
    "Its applied in various fields such as machine learning, medical diagnosis, spam filtering, and more. \n",
    "The strength of Bayes theorem lies in its ability to incorporate new evidence and adjust probabilities accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d745acc-e80c-474e-876f-bf0950c9e7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43acce0a-1d7f-4fd7-b3c6-e0ac96d27aa3",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d56845f-af93-400d-b668-66da2c4c4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 4:-Bayes theorem is closely related to conditional probability, and it provides a way to update probabilities based on new evidence. \n",
    "The relationship between Bayes theorem and conditional probability can be understood through the theorem itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7903e-0ca6-498f-a534-d08aa190e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes theorem expresses the relationship between the conditional probability of an event A given evidence B(P(A∣B)) and the prior probability of A (P(A)), the \n",
    "conditional probability of observing B given A (P(B∣A)), and the total probability of observing B (P(B)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c00779-c163-45ce-a2bc-251f5c3cd260",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conditional Probability:\n",
    "    P(A|B):This is the posterior probability of event A given the evidence B.\n",
    "    P(A):The prior probability of event A before considering evidence B.\n",
    "    P(B|A):The probability of observing evidence B given that A is true.\n",
    "    \n",
    "Prior Probability:\n",
    "    The term P(A)  is the prior probability of event A, which represents the initial probability of A before considering any new evidence.\n",
    "    \n",
    "Evidence Probability:\n",
    "    The term P(B|A) is the conditional probability of observing evidence B given that A  is true. It represents the likelihood of the observed evidence under the \n",
    "    assumption that A is true.\n",
    "    \n",
    "Total Probability:\n",
    "    P(B) The total probability of observing evidence B regardless of whether A s true or false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d4150-9292-464d-a816-8e3570fd0a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c99df027-c00f-4440-a03c-fc2d1fc4ac69",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d663fc3-3aae-4af4-9145-1087f1ec8f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 5:-The choice of which type of Naive Bayes classifier to use depends on the nature of the data and the assumptions that are reasonable for the given problem. \n",
    "Heres a brief overview of three common types of Naive Bayes classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce161c91-0b35-4d03-ac28-c44ea81c2923",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gaussian Naive Bayes:\n",
    "\n",
    "Assumption: Assumes that the features follow a Gaussian distribution (bell curve).\n",
    "Use Case: Suitable for continuous numerical data.\n",
    "Multinomial Naive Bayes:\n",
    "\n",
    "Assumption: Assumes that the features are multinomially distributed, which is suitable for discrete data (e.g., word counts in text classification).\n",
    "Use Case: Commonly used for text classification tasks where the data is represented as word frequency counts.\n",
    "Bernoulli Naive Bayes:\n",
    "\n",
    "Assumption: Assumes that features are binary (i.e., presence or absence of a feature).\n",
    "Use Case: Suitable for binary and sparse data, often used in text classification tasks where the presence or absence of words is considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae49a3-95dc-491c-a603-081d1c3dd056",
   "metadata": {},
   "outputs": [],
   "source": [
    "Choosing the Right Type:\n",
    "\n",
    "Nature of Features: \n",
    "    Consider the nature of your features. \n",
    "    If they are continuous, Gaussian Naive Bayes might be appropriate.\n",
    "    If they are discrete and represent counts, Multinomial Naive Bayes might be suitable. \n",
    "    For binary data, Bernoulli Naive Bayes is a good choice.\n",
    "\n",
    "Data Distribution: \n",
    "    If your data doesnt precisely follow the assumed distribution of a particular Naive Bayes classifier, you might still try different types and evaluate their \n",
    "    performance. \n",
    "    Naive Bayes is known for its simplicity, and sometimes it performs surprisingly well even when assumptions are not perfectly met.\n",
    "\n",
    "Size of Dataset: \n",
    "    In practice, the performance of Naive Bayes classifiers, especially Multinomial and Bernoulli, can be robust even with relatively small datasets.\n",
    "\n",
    "Experimentation: \n",
    "    Often, the best way to choose is to try different types and assess their performance through techniques like cross-validation. \n",
    "    The performance of a classifier depends on the specific characteristics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450bc5d0-e197-4630-af8b-4d2ae3590086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd1385ea-1da8-4a22-b2a7-464df594f826",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36289121-d6d5-44d6-b2bb-7534f37de6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 6:-To predict the class for the new instance using Naive Bayes, we will calculate the likelihood for each class given the observed feature values and then apply \n",
    "Bayes' theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c61a5cc-d9f2-465f-9483-b7841e76295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P(A) and P(B) as the prior probabilities for classes A and B, respectively. Since its mentioned that the prior probabilities are equal P(A)=P(B)=0.5\n",
    "P(X1=3∣A),P(X2=4|A),P(X1=3|B),P(X2=4|B)as the likelihoods of each feature value given each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da051b-fc44-4c0f-9df5-9d279f31c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "The likelihoods are calculated from the provided table. For example,P(X1=3|A) is the proportion of times X1 is 3 in class A, which is 4/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51d390-113a-47c2-884c-296a3ab5e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "The prediction is made by comparing the posterior probabilities for each class. According to Bayes' theorem:\n",
    "P(A|X1=3,X2=4)∝P(A).P(X1=3|A).P(X2=4|A)\n",
    "P(B|X1=3,X2=4)∝P(B).P(X1=3|B).P(X2=4|B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
