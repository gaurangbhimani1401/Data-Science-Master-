{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5674ecd-7b2c-4598-96b5-c59218b30d24",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac55e55-de97-40dd-87f6-86063bf22d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 1:- Simple Linear Regression and Multiple Linear Regression are both techniques used in the field of regression analysis, a statistical method for modeling the\n",
    "        relationship between a dependent variable and one or more independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10775432-4337-4c23-86b2-3977307fcb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Simple Linear Regression:\n",
    "    In Simple Linear Regression, there is one dependent variable (Y) and one independent variable (X).\n",
    "    It models the linear relationship between the dependent variable and the independent variable using a straight line (Y = aX + b).\n",
    "    It is used when you want to predict a continuous outcome based on a single predictor variable.\n",
    "    For example, you can use simple linear regression to predict a student's final exam score (Y) based on the number of hours they studied (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4486049-b48c-474b-96aa-596b6818fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple Linear Regression:\n",
    "    In Multiple Linear Regression, there is one dependent variable (Y) and multiple independent variables (X1, X2, X3, ... Xn).\n",
    "    It models the linear relationship between the dependent variable and multiple independent variables using a linear equation (Y = aX1 + bX2 + cX3 + ... + nXn + d).\n",
    "    It is used when you want to predict a continuous outcome based on multiple predictor variables that may have an impact on the outcome.\n",
    "    For example, you can use multiple linear regression to predict a houses sale price (Y) based on various factors like the number of bedrooms (X1),\n",
    "    square footage (X2), and neighborhood quality (X3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ab773-0d96-4536-bf3b-9fb628010780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab2f6882-e5f0-4fde-99af-9f72d6063419",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17737d85-3857-42d8-86e3-de6fdac8ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 2:-Linear regression relies on several assumptions to be valid.\n",
    "       Violation of these assumptions can affect the accuracy and interpretability of the regression model.\n",
    "       Here are the key assumptions of linear regression, along with methods to check if they hold in a given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26b207-d8d5-4be0-8511-762e4e7facd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Linearity:\n",
    "    The relationship between the independent variables and the dependent variable should be linear.\n",
    "    You can check this assumption by creating scatter plots of the dependent variable against each independent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f972e-e57e-4397-b4d3-5235ee52533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Independence:\n",
    "    The residuals (errors) should be independent of each other.\n",
    "    This means that the value of the dependent variable for one data point should not influence the value of the dependent variable for another data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f216e-2c82-4c9e-be69-e5ae17b5a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Homoscedasticity:\n",
    "    Homoscedasticity means that the variance of the residuals should be constant across all levels of the independent variables. \n",
    "    You can create a scatter plot of residuals against the predicted values or independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208c9510-2212-4608-b534-d9fbecdb89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Normality of Residuals:\n",
    "    The residuals should follow a normal distribution.\n",
    "    You can assess this assumption by creating a histogram of the residuals and checking if it roughly resembles a bell-shaped curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fac1a7-cafe-45d7-b7a3-e9ca58a9db96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d8c596d-e233-47ba-a2e6-2579b148b06f",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3fca1b-1a87-497b-b547-ce52f562c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 3:-\n",
    "1. Slope (Coefficient of the Independent Variable):\n",
    "    The slope represents the change in the dependent variable (Y) for a one-unit change in the independent variable (X), holding all other independent variables\n",
    "    constant.\n",
    "    It indicates the strength and direction of the linear relationship between the independent variable and the dependent variable.\n",
    "    A positive slope means that as X increases, Y is expected to increase, while a negative slope means that as X increases, Y is expected to decrease.\n",
    "    The magnitude of the slope tells you the extent of the change in Y associated with a one-unit change in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098a8b0-f6fb-4f66-823d-5a7421007799",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Intercept (Y-Intercept or Constant Term):\n",
    "    The intercept is the expected value of the dependent variable when all independent variables are set to zero.\n",
    "    In some cases, the intercept may have no practical meaning.\n",
    "    For example, if you are predicting a persons weight based on the number of hours they exercise, it may not make sense to have an interpretation for the weight\n",
    "    when exercise hours are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e172e-ebf3-4dd1-afb1-f44ba64fd6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scenario: Predicting House Prices\n",
    "\n",
    "Suppose youre a real estate agent, and you want to predict house prices based on their size (in square feet) and the number of bedrooms in the house.\n",
    "You collect data on several houses and fit a linear regression model:\n",
    "\n",
    "The slope for the \"Size\" variable is 100, which means that for every additional square foot of living space, the house price is expected to increase by $100,\n",
    "holding the number of bedrooms constant.\n",
    "The slope for the \"Number of Bedrooms\" variable is 10, indicating that for each additional bedroom, the house price is expected to increase by $10, assuming the\n",
    "size remains the same.\n",
    "The intercept is $50,000, which represents the expected house price when a house has zero square feet (which doesn't make practical sense in this context).\n",
    "So, the linear regression model equation is:\n",
    "\n",
    "House Price = $50,000 (intercept) + $100 (per square foot) * Size + $10 (per bedroom) * Number of Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c71f8-8bc4-4d72-92a3-38e4218a8f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dcdcb2f-e306-43ca-afff-806eb99c13be",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7f80e9-ebdf-4e75-b516-0bbbe2e5acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 4:-\n",
    "Gradient Descent is an optimization algorithm used in machine learning and deep learning to minimize a cost function or loss function.\n",
    "It is a fundamental method for finding the optimal parameters (weights and biases) of a machine learning model, typically in the context of training models\n",
    "like linear regression, logistic regression, neural networks, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c021e7-aca0-4e0f-a1ac-9ba1f24fa893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe8a7acb-8135-4bb8-88d9-72009ebe01c9",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c13bc-a4b0-434a-8c16-1891c6a02b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 5:-Multiple Linear Regression is an extension of simple linear regression, which allows us to model the relationship between a dependent variable and multiple\n",
    "       independent variables.\n",
    "    In simple linear regression, we have one dependent variable and one independent variable, while in multiple linear regression, we have one dependent variable\n",
    "    and two or more independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8303e-3cf9-41b8-b351-ef4f9966672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Model Equation:\n",
    "    Simple Linear Regression:\n",
    "        In simple linear regression, the model equation is of the form Y = aX + b, where Y is the dependent variable, X is the independent variable, 'a' is the slope\n",
    "        (coefficient), and 'b' is the intercept.\n",
    "        \n",
    "    Multiple Linear Regression:\n",
    "        In multiple linear regression, the model equation is extended to include multiple independent variables.\n",
    "        It takes the form Y = a1X1 + a2X2 + ... + anXn + b, where Y is the dependent variable, X1, X2, ..., Xn are the independent variables, and a1, a2, ..., an are\n",
    "        the respective coefficients (slopes) for each independent variable, and 'b' is the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf695b-fc16-48bd-b742-922eaf3fd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Number of Independent Variables:\n",
    "    Simple Linear Regression:\n",
    "        Only one independent variable is considered.\n",
    "    Multiple Linear Regression:\n",
    "        Two or more independent variables are included.\n",
    "        \n",
    "3. Interpretation of Coefficients:\n",
    "    In simple linear regression, there is a single coefficient representing the relationship between the dependent variable and the independent variable.\n",
    "    In multiple linear regression, each coefficient represents the relationship between the dependent variable and a specific independent variable,\n",
    "    holding all other independent variables constant.\n",
    "    This allows us to analyze the impact of each independent variable while controlling for the presence of other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2ca5e-9999-427a-984a-12df47eea174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e7bede2-cdf1-47c6-ad2c-e2343cafd9ea",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd28de3-f1f2-47fe-a8c0-7dce7181cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 6:-\n",
    "Multicollinearity is a common issue in multiple linear regression, and it occurs when two or more independent variables in a regression model are highly\n",
    "correlated with each other.\n",
    "In other words, multicollinearity means that some independent variables can be linearly predicted from the others, which can lead to problems in the model\n",
    "estimation and interpretation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0078be-4b53-4166-b654-d04d710f2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Causes of Multicollinearity:\n",
    "    Data Collection:\n",
    "        Multicollinearity often arises from how data is collected.\n",
    "        For example, if you have both \"height in feet\" and \"height in inches\" as independent variables, they are highly correlated because they contain redundant\n",
    "        information.\n",
    "\n",
    "    Highly Related Variables:\n",
    "        Some variables may naturally be highly correlated due to their relationship.\n",
    "        For example, in a housing price prediction model, the variables \"number of bedrooms\" and \"square footage\" are often related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7054a-deb4-4278-a82a-0a2cb10577ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Impact of Multicollinearity:\n",
    "    Inflated Standard Errors:\n",
    "        Multicollinearity can lead to inflated standard errors of the regression coefficients, making it difficult to determine which independent variables\n",
    "        are significant.\n",
    "\n",
    "Unstable Coefficients:\n",
    "    Small changes in the data can lead to substantial changes in the estimated coefficients, making the model less reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f791d77-ccf9-476d-8271-1f81afeb2c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "578e6b6d-6e99-426d-a8c8-16fa018dec83",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfedb4-fb31-4385-bf9e-6eadd6221c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 7:-\n",
    "Polynomial Regression is a type of regression analysis that models the relationship between the dependent variable and one or more independent variables as an\n",
    "nth-degree polynomial.\n",
    "In contrast to simple linear regression, which fits a straight line to the data, polynomial regression uses higher-degree polynomials to capture non-linear\n",
    "relationships. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ec805-9daa-473a-b8e7-f42a10f0f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Functional Form:\n",
    "    Linear regression fits a straight line (first-degree polynomial) to the data, assuming a linear relationship between variables.\n",
    "    Polynomial regression allows for more flexible functional forms, including curves, parabolas, and higher-order polynomials.\n",
    "\n",
    "Degree of Complexity:\n",
    "    Polynomial regression introduces more complexity by including higher-degree terms (e.g., X², X³) in the equation.\n",
    "    This flexibility allows it to capture non-linear relationships, which linear regression cannot represent.\n",
    "\n",
    "Interpretation:\n",
    "    Linear regression provides straightforward interpretations of coefficients for independent variables, representing the change in the dependent variable\n",
    "    for a one-unit change in the independent variable.\n",
    "    In polynomial regression, the interpretation of coefficients becomes more complex as they relate to various powers of the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f59fd-f2fd-4b59-9a57-849d8f79ad53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad290cc6-97e9-47ba-9930-55a5d4ca7dc4",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e4633-df1d-498a-9262-6db05feac67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 8:-\n",
    "Advantages of Polynomial Regression Compared to Linear Regression:\n",
    "\n",
    "Capturing Non-Linear Relationships:\n",
    "    Polynomial regression can model complex, non-linear relationships between the dependent and independent variables.\n",
    "    This flexibility makes it suitable for scenarios where linear regression would be inadequate.\n",
    "\n",
    "Increased Model Fit:\n",
    "    In cases where the data exhibits non-linear patterns, a polynomial regression model is more likely to fit the data accurately compared to linear regression.\n",
    "    It can reduce the bias in the model by capturing curvilinear or quadratic patterns.\n",
    "\n",
    "Enhanced Accuracy:\n",
    "    Polynomial regression can provide more accurate predictions when the true relationship between variables is non-linear.\n",
    "    It can improve the models accuracy and reduce prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ec5b5-ad11-4a6b-95f4-62dd7da9240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Disadvantages of Polynomial Regression Compared to Linear Regression:\n",
    "\n",
    "Overfitting:\n",
    "    Polynomial regression models are susceptible to overfitting, especially when the degree of the polynomial is high.\n",
    "    Overfitting occurs when the model fits the training data too closely and fails to generalize to new data.\n",
    "    Proper model validation is crucial to avoid overfitting.\n",
    "\n",
    "Complexity:\n",
    "    Higher-degree polynomials introduce more complexity into the model.\n",
    "    This complexity can make the interpretation of coefficients and model behavior less intuitive compared to linear regression.\n",
    "\n",
    "Lack of Linearity:\n",
    "    Polynomial regression may not be suitable for cases where the relationship between variables is genuinely linear.\n",
    "    In such cases, a simpler linear regression model may provide more straightforward and interpretable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38173409-e00a-4658-ae0c-b4e03b8eeee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "When to Prefer Polynomial Regression:\n",
    "\n",
    "Polynomial regression is preferable in the following situations:\n",
    "\n",
    "Non-Linear Relationships:\n",
    "    When it is evident that the relationship between the dependent and independent variables is non-linear, polynomial regression is a suitable choice.\n",
    "\n",
    "Curvilinear Patterns:\n",
    "    In scenarios where the relationship exhibits curvilinear or quadratic patterns, polynomial regression allows you to capture these patterns accurately.\n",
    "\n",
    "Improved Model Fit:\n",
    "    When the aim is to improve the models fit to the data, especially if linear regression does not adequately represent the relationship."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
